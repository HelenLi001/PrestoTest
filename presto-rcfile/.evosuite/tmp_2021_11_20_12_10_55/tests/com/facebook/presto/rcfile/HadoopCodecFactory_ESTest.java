/*
 * This file was automatically generated by EvoSuite
 * Sat Nov 20 20:41:10 GMT 2021
 */

package com.facebook.presto.rcfile;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import com.facebook.presto.rcfile.HadoopCodecFactory;
import com.facebook.presto.rcfile.RcFileCompressor;
import com.facebook.presto.rcfile.RcFileDecompressor;
import org.apache.hadoop.io.compress.BZip2Codec;
import org.apache.hadoop.io.compress.DeflateCodec;
import org.apache.hadoop.io.compress.GzipCodec;
import org.apache.hadoop.io.compress.Lz4Codec;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class HadoopCodecFactory_ESTest extends HadoopCodecFactory_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test0()  throws Throwable  {
      Class<Lz4Codec> class0 = Lz4Codec.class;
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn(class0).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      assertNotNull(hadoopCodecFactory0);
      
      // Undeclared exception!
      try { 
        hadoopCodecFactory0.createDecompressor("U7}%/Nc7s.\"FYh");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // native lz4 library not available
         //
         verifyException("org.apache.hadoop.io.compress.Lz4Codec", e);
      }
  }

  @Test(timeout = 4000)
  public void test1()  throws Throwable  {
      Class<BZip2Codec> class0 = BZip2Codec.class;
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn(class0).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      assertNotNull(hadoopCodecFactory0);
      
      // Undeclared exception!
      try { 
        hadoopCodecFactory0.createDecompressor((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("com.facebook.presto.rcfile.HadoopCodecFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test2()  throws Throwable  {
      Class<GzipCodec> class0 = GzipCodec.class;
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn(class0).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      assertNotNull(hadoopCodecFactory0);
      
      // Undeclared exception!
      try { 
        hadoopCodecFactory0.createDecompressor("]");
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class org.apache.hadoop.util.Shell
         //
         verifyException("org.apache.hadoop.util.DataChecksum", e);
      }
  }

  @Test(timeout = 4000)
  public void test3()  throws Throwable  {
      Class<Object> class0 = Object.class;
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn(class0).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      assertNotNull(hadoopCodecFactory0);
      
      // Undeclared exception!
      try { 
        hadoopCodecFactory0.createDecompressor("}+yR");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
      }
  }

  @Test(timeout = 4000)
  public void test4()  throws Throwable  {
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn((Class) null).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      assertNotNull(hadoopCodecFactory0);
      
      // Undeclared exception!
      try { 
        hadoopCodecFactory0.createCompressor("n$8JuqF9?yFr{Dz");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("com.facebook.presto.rcfile.HadoopCodecFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test5()  throws Throwable  {
      Class<String> class0 = String.class;
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn(class0).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      assertNotNull(hadoopCodecFactory0);
      
      // Undeclared exception!
      try { 
        hadoopCodecFactory0.createCompressor("d#6g,&2Rx9Z");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
      }
  }

  @Test(timeout = 4000)
  public void test6()  throws Throwable  {
      Class<DeflateCodec> class0 = DeflateCodec.class;
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn(class0).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      RcFileDecompressor rcFileDecompressor0 = hadoopCodecFactory0.createDecompressor("J.p\u0006I;E!LXdR_");
      assertNotNull(rcFileDecompressor0);
  }

  @Test(timeout = 4000)
  public void test7()  throws Throwable  {
      Class<DeflateCodec> class0 = DeflateCodec.class;
      ClassLoader classLoader0 = mock(ClassLoader.class, new ViolatedAssumptionAnswer());
      doReturn(class0).when(classLoader0).loadClass(anyString());
      HadoopCodecFactory hadoopCodecFactory0 = new HadoopCodecFactory(classLoader0);
      RcFileCompressor rcFileCompressor0 = hadoopCodecFactory0.createCompressor("J.p\u0006I;E!LXdR_");
      assertNotNull(rcFileCompressor0);
  }
}
